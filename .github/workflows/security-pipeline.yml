name: Optimized Flutter Security Pipeline

on:
  push:
    branches: [main, develop]
    paths:
      - 'lib/**'
      - 'test/**'
      - 'pubspec.yaml'
      - 'pubspec.lock'
      - '.github/workflows/**'
      - 'scripts/**'
      
  pull_request:
    branches: [main]
    types: [opened, synchronize, reopened]

  schedule:
    - cron: '0 0 * * 1'  # Weekly security scan
    
  workflow_dispatch:
    inputs:
      scan_type:
        description: 'Scan type'
        required: true
        default: 'full'
        type: choice
        options:
          - incremental
          - full
          - critical-only

concurrency:
  group: security-${{ github.workflow }}-${{ github.ref_name }}
  cancel-in-progress: ${{ github.event_name == 'pull_request' }}

permissions:
  contents: read
  id-token: write
  security-events: write
  actions: read

env:
  # Core versions
  FLUTTER_VERSION: '3.19.0'
  DART_VERSION: '3.3.0'
  
  # Security tool versions
  SYFT_VERSION: 'v1.29.0'
  GRYPE_VERSION: 'v0.74.1'
  TRIVY_VERSION: 'v0.48.1'
  SEMGREP_VERSION: 'v1.45.0'
  
  # Security configuration
  GRYPE_FAIL_ON_SEVERITY: high
  TRIVY_SEVERITY: CRITICAL,HIGH,MEDIUM
  
  # Timeout settings
  TIMEOUT_MINUTES: 30

jobs:
  # Pre-check - Fast fail
  pre-check:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      should_run: ${{ steps.check.outputs.should_run }}
      scan_type: ${{ steps.check.outputs.scan_type }}
      changed_files: ${{ steps.check.outputs.changed_files }}
      base_sha: ${{ steps.check.outputs.base_sha }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - id: check
        run: |
          # Determine scan type and check if should run
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            BASE_SHA="${{ github.event.pull_request.base.sha }}"
            CURRENT_SHA="${{ github.sha }}"
          else
            BASE_SHA="${{ github.event.before }}"
            CURRENT_SHA="${{ github.sha }}"
          fi
          
          echo "base_sha=$BASE_SHA" >> $GITHUB_OUTPUT
          
          # Override with manual input if provided
          if [[ "${{ github.event.inputs.scan_type }}" != "" ]]; then
            echo "scan_type=${{ github.event.inputs.scan_type }}" >> $GITHUB_OUTPUT
            echo "should_run=true" >> $GITHUB_OUTPUT
          elif [[ "${{ github.event_name }}" == "schedule" ]]; then
            echo "scan_type=full" >> $GITHUB_OUTPUT
            echo "should_run=true" >> $GITHUB_OUTPUT
          elif [[ "${{ github.event_name }}" == "pull_request" ]]; then
            if [[ "$BASE_SHA" != "0000000000000000000000000000000000000000" ]]; then
              CHANGED=$(git diff --name-only $BASE_SHA $CURRENT_SHA | grep -E '\.(dart|yaml)$' | wc -l)
              if [ $CHANGED -eq 0 ]; then
                echo "should_run=false" >> $GITHUB_OUTPUT
              else
                echo "should_run=true" >> $GITHUB_OUTPUT
                echo "scan_type=incremental" >> $GITHUB_OUTPUT
                
                CHANGED_FILES=$(git diff --name-only $BASE_SHA $CURRENT_SHA | grep -E '\.(dart|yaml)$' || true)
                echo "changed_files<<EOF" >> $GITHUB_OUTPUT
                echo "$CHANGED_FILES" >> $GITHUB_OUTPUT
                echo "EOF" >> $GITHUB_OUTPUT
              fi
            else
              echo "should_run=true" >> $GITHUB_OUTPUT
              echo "scan_type=full" >> $GITHUB_OUTPUT
            fi
          else
            echo "should_run=true" >> $GITHUB_OUTPUT
            echo "scan_type=full" >> $GITHUB_OUTPUT
          fi

  # Cache setup
  setup-and-cache:
    runs-on: ubuntu-latest
    needs: pre-check
    if: needs.pre-check.outputs.should_run == 'true'
    outputs:
      cache-hit: ${{ steps.cache.outputs.cache-hit }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Install parsing helpers
        run: |
          sudo apt-get update && sudo apt-get install -y jq yq python3-yaml
          
      - name: Update security databases
        run: |
          # Install and update Grype database
          wget -qO- https://raw.githubusercontent.com/anchore/grype/main/install.sh | sh
          export PATH="$PWD/bin:$PATH"
          grype db update
          
      - name: Enhanced Cache Strategy
        id: cache
        uses: actions/cache@v4
        with:
          path: |
            ~/.pub-cache
            .dart_tool
            .packages
            ~/.cache/semgrep
            ~/.cache/trivy
            ~/.grype/db
            ~/.syft/db
            ~/security-tools
          key: ${{ runner.os }}-flutter-${{ env.FLUTTER_VERSION }}-${{ hashFiles('**/pubspec.lock') }}
          restore-keys: |
            ${{ runner.os }}-flutter-${{ env.FLUTTER_VERSION }}-
            ${{ runner.os }}-flutter-

  # Independent SBOM generation
  generate-sbom:
    runs-on: ubuntu-latest
    needs: [pre-check, setup-and-cache]
    if: needs.pre-check.outputs.should_run == 'true'
    timeout-minutes: 10
    
    steps:
      - uses: actions/checkout@v4
        
      - name: Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          
      - name: Get dependencies
        run: flutter pub get
        
      - name: Generate comprehensive SBOM
        run: |
          # Install Syft
          curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b /usr/local/bin
          syft --version
          
          # Generate Syft SBOM
          syft . --output cyclonedx-json=syft-sbom.json
          
          # Generate Flutter-specific SBOM
          cat > generate-flutter-sbom.dart << 'EOF'
          import 'dart:io';
          import 'dart:convert';
          
          void main() async {
            try {
              // Run flutter pub deps command
              final result = await Process.run('flutter', ['pub', 'deps', '--json']);
              if (result.exitCode != 0) {
                print('Error running flutter pub deps: ${result.stderr}');
                exit(1);
              }
              
              final depsData = json.decode(result.stdout);
              
              // Read pubspec.yaml for metadata
              final pubspecFile = File('pubspec.yaml');
              final pubspecContent = await pubspecFile.readAsString();
              
              // Extract name and version (simple parsing)
              String appName = 'unknown';
              String appVersion = '0.0.0';
              String description = '';
              
              for (final line in pubspecContent.split('\n')) {
                if (line.startsWith('name:')) {
                  appName = line.split(':')[1].trim();
                } else if (line.startsWith('version:')) {
                  appVersion = line.split(':')[1].trim().split('+')[0]; // Remove build number
                } else if (line.startsWith('description:')) {
                  description = line.split(':')[1].trim();
                }
              }
              
              // Generate SBOM
              final sbom = {
                'bomFormat': 'CycloneDX',
                'specVersion': '1.4',
                'serialNumber': 'urn:uuid:${DateTime.now().millisecondsSinceEpoch}',
                'version': 1,
                'metadata': {
                  'timestamp': DateTime.now().toIso8601String(),
                  'tools': [{
                    'vendor': 'Flutter Security Scanner',
                    'name': 'flutter-sbom-generator',
                    'version': '1.0.0'
                  }],
                  'component': {
                    'type': 'application',
                    'bom-ref': appName,
                    'name': appName,
                    'version': appVersion,
                    'description': description,
                  }
                },
                'components': []
              };
              
              // Process dependencies
              final components = <Map<String, dynamic>>[];
              for (var package in depsData['packages']) {
                if (package['name'] != appName) {
                  components.add({
                    'type': 'library',
                    'bom-ref': 'pkg:pub/${package['name']}@${package['version']}',
                    'name': package['name'],
                    'version': package['version'],
                    'purl': 'pkg:pub/${package['name']}@${package['version']}',
                    'scope': package['kind'] == 'direct' ? 'required' : 'optional',
                  });
                }
              }
              sbom['components'] = components;
              
              // Write SBOM
              final sbomFile = File('flutter-sbom.json');
              await sbomFile.writeAsString(
                JsonEncoder.withIndent('  ').convert(sbom)
              );
              print('Flutter SBOM generated successfully');
              print('Total components: ${components.length}');
            } catch (e, stack) {
              print('Error generating Flutter SBOM: $e');
              print('Stack trace: $stack');
              exit(1);
            }
          }
          EOF
          
          dart run generate-flutter-sbom.dart
          
          # Merge SBOMs
          jq -s '.[0] * {components: (.[0].components + .[1].components)}' \
            syft-sbom.json flutter-sbom.json > sbom.json
            
          # Generate dependency tree
          flutter pub deps --style=tree > dependency-tree.txt
          
          # Generate outdated report
          flutter pub outdated --json > outdated.json || echo '{}' > outdated.json
          
      - name: Upload SBOM artifacts
        uses: actions/upload-artifact@v4
        with:
          name: software-bill-of-materials
          path: |
            sbom.json
            syft-sbom.json
            flutter-sbom.json
            dependency-tree.txt
            outdated.json
          retention-days: 90

  # Dependency vulnerability scanning
  dependency-vulnerability-scan:
    needs: [generate-sbom]
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - uses: actions/checkout@v4
        
      - name: Download SBOM
        uses: actions/download-artifact@v4
        with:
          name: software-bill-of-materials
          
      - name: Vulnerability scanning suite
        run: |
          # Install tools
          curl -sSfL https://raw.githubusercontent.com/anchore/grype/main/install.sh | sh -s -- -b /usr/local/bin
          
          # Grype scan
          grype sbom:sbom.json --output sarif --file grype-results.sarif || {
            EXIT_CODE=$?
            echo "Grype scan completed with exit code: $EXIT_CODE"
            if [ ! -f "grype-results.sarif" ]; then
              echo '{"version": "2.1.0", "runs": []}' > grype-results.sarif
            fi
          }
          
          # OSV Scanner
          wget -q https://github.com/google/osv-scanner/releases/latest/download/osv-scanner_linux_amd64
          chmod +x osv-scanner_linux_amd64
          ./osv-scanner_linux_amd64 --sbom=sbom.json --format=json > osv-results.json || {
            EXIT_CODE=$?
            echo "OSV Scanner completed with exit code: $EXIT_CODE"
            if [ ! -f "osv-results.json" ] || [ ! -s "osv-results.json" ]; then
              echo '{"results": []}' > osv-results.json
            fi
          }
          
      - name: Trivy filesystem scan
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: ${{ env.TRIVY_SEVERITY }}
          
      - name: Upload vulnerability scan results
        uses: actions/upload-artifact@v4
        with:
          name: vulnerability-scan-results
          path: |
            grype-results.sarif
            trivy-results.sarif
            osv-results.json
          retention-days: 30

  # Static Application Security Testing (SAST)
  sast-scan:
    needs: [pre-check, setup-and-cache]
    if: needs.pre-check.outputs.should_run == 'true'
    strategy:
      fail-fast: false
      max-parallel: 3
      matrix:
        include:
          - tool: semgrep
            config: 'p/security-audit p/dart p/flutter p/owasp-top-ten'
            timeout: 10
          - tool: flutter-analyzer
            timeout: 8
          - tool: dcm
            timeout: 10
    
    runs-on: ubuntu-latest
    timeout-minutes: ${{ matrix.timeout }}
    
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          channel: 'stable'
          
      - name: Get dependencies
        run: flutter pub get
          
      - name: Install security tools
        run: |
          if [[ "${{ matrix.tool }}" == "semgrep" ]]; then
            pipx install "semgrep==${{ env.SEMGREP_VERSION }}"
          elif [[ "${{ matrix.tool }}" == "dcm" ]]; then
            dart pub global activate dart_code_metrics
          fi
          
      - name: Run security analysis
        run: |
          case "${{ matrix.tool }}" in
            semgrep)
              semgrep --config=${{ matrix.config }} --sarif > ${{ matrix.tool }}-results.sarif || {
                echo "Semgrep found issues"
                if [ ! -f "${{ matrix.tool }}-results.sarif" ]; then
                  echo '{"version": "2.1.0", "runs": []}' > ${{ matrix.tool }}-results.sarif
                fi
              }
              ;;
            flutter-analyzer)
              dart analyze --format=machine > ${{ matrix.tool }}-results.txt || {
                echo "Flutter analyzer found issues"
                touch ${{ matrix.tool }}-results.txt
              }
              # Convert to SARIF format
              cat > convert-to-sarif.dart << 'EOFD'
              import 'dart:io';
              import 'dart:convert';
              
              void main() async {
                final input = File('flutter-analyzer-results.txt');
                if (!await input.exists()) {
                  // Create empty SARIF
                  final emptySarif = {
                    'version': '2.1.0',
                    '\$schema': 'https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json',
                    'runs': [{
                      'tool': {
                        'driver': {
                          'name': 'flutter-analyzer',
                          'version': '1.0.0'
                        }
                      },
                      'results': []
                    }]
                  };
                  await File('flutter-analyzer-results.sarif').writeAsString(
                    JsonEncoder.withIndent('  ').convert(emptySarif)
                  );
                  return;
                }
                
                final lines = await input.readAsLines();
                final results = [];
                
                for (final line in lines) {
                  if (line.contains('•')) {
                    final parts = line.split('•');
                    if (parts.length >= 3) {
                      final location = parts[0].trim();
                      final severity = parts[1].trim();
                      final message = parts[2].trim();
                      
                      // Parse file path and line number
                      final locationParts = location.split(':');
                      if (locationParts.length >= 2) {
                        results.add({
                          'ruleId': 'flutter-analyzer',
                          'level': severity.toLowerCase() == 'error' ? 'error' : 'warning',
                          'message': {'text': message},
                          'locations': [{
                            'physicalLocation': {
                              'artifactLocation': {
                                'uri': locationParts[0]
                              },
                              'region': {
                                'startLine': int.tryParse(locationParts[1]) ?? 1
                              }
                            }
                          }]
                        });
                      }
                    }
                  }
                }
                
                final sarif = {
                  'version': '2.1.0',
                  '\$schema': 'https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json',
                  'runs': [{
                    'tool': {
                      'driver': {
                        'name': 'flutter-analyzer',
                        'version': '1.0.0'
                      }
                    },
                    'results': results
                  }]
                };
                
                await File('flutter-analyzer-results.sarif').writeAsString(
                  JsonEncoder.withIndent('  ').convert(sarif)
                );
              }
              EOFD
              
              dart run convert-to-sarif.dart
              ;;
            dcm)
              dart pub global run dart_code_metrics:metrics analyze lib --reporter=sarif:${{ matrix.tool }}-results.sarif || {
                echo "DCM analysis found issues"
                if [ ! -f "${{ matrix.tool }}-results.sarif" ]; then
                  echo '{"version": "2.1.0", "runs": []}' > ${{ matrix.tool }}-results.sarif
                fi
              }
              ;;
          esac
          
      - name: Upload SAST results
        uses: actions/upload-artifact@v4
        with:
          name: sast-${{ matrix.tool }}-results
          path: |
            ${{ matrix.tool }}-results.sarif
            ${{ matrix.tool }}-results.txt
          retention-days: 30

  # Supply chain security
  supply-chain-security:
    needs: [generate-sbom]
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          
      - name: Download SBOM
        uses: actions/download-artifact@v4
        with:
          name: software-bill-of-materials
          
      - name: License compliance check
        run: |
          # Create license check script
          cat > check-licenses.py << 'EOF'
          import json
          import sys
          from datetime import datetime
          
          # Prohibited licenses
          PROHIBITED_LICENSES = [
              'GPL', 'GPL-2.0', 'GPL-3.0', 
              'AGPL', 'AGPL-3.0',
              'LGPL', 'LGPL-2.1', 'LGPL-3.0',
              'SSPL', 'OSL'
          ]
          
          # Warning licenses
          WARNING_LICENSES = [
              'MPL', 'MPL-2.0',
              'CC-BY-SA', 'CC-BY-NC'
          ]
          
          def check_licenses(sbom_file):
              with open(sbom_file, 'r') as f:
                  sbom = json.load(f)
              
              report = {
                  'timestamp': datetime.now().isoformat(),
                  'compliant': True,
                  'violations': [],
                  'warnings': [],
                  'summary': {
                      'total_packages': 0,
                      'prohibited_licenses': 0,
                      'warning_licenses': 0
                  }
              }
              
              components = sbom.get('components', [])
              report['summary']['total_packages'] = len(components)
              
              for component in components:
                  name = component.get('name', 'unknown')
                  version = component.get('version', 'unknown')
                  licenses = component.get('licenses', [])
                  
                  for license_info in licenses:
                      license_id = license_info.get('license', {}).get('id', '')
                      
                      if any(prohibited in license_id.upper() for prohibited in PROHIBITED_LICENSES):
                          report['violations'].append({
                              'package': name,
                              'version': version,
                              'license': license_id,
                              'severity': 'HIGH'
                          })
                          report['summary']['prohibited_licenses'] += 1
                          report['compliant'] = False
                      elif any(warning in license_id.upper() for warning in WARNING_LICENSES):
                          report['warnings'].append({
                              'package': name,
                              'version': version,
                              'license': license_id,
                              'severity': 'MEDIUM'
                          })
                          report['summary']['warning_licenses'] += 1
              
              with open('license-compliance-report.json', 'w') as f:
                  json.dump(report, f, indent=2)
              
              print(f"License compliance check completed")
              print(f"Total packages: {report['summary']['total_packages']}")
              print(f"Prohibited licenses: {report['summary']['prohibited_licenses']}")
              print(f"Warning licenses: {report['summary']['warning_licenses']}")
              
              return report['compliant']
          
          if __name__ == '__main__':
              compliant = check_licenses('sbom.json')
              sys.exit(0 if compliant else 1)
          EOF
          
          python3 check-licenses.py || echo "License compliance issues found"
          
      - name: Secret scanning
        run: |
          # Install and run TruffleHog
          pip install trufflesecurity-trufflehog
          
          trufflehog filesystem . --json > secret-scan-results.json || {
            EXIT_CODE=$?
            echo "TruffleHog scan completed with exit code: $EXIT_CODE"
            if [ ! -s "secret-scan-results.json" ]; then
              echo '{"results": []}' > secret-scan-results.json
            fi
          }
          
          # Count secrets found
          if [ -f "secret-scan-results.json" ]; then
            SECRET_COUNT=$(grep -c '"SourceMetadata"' secret-scan-results.json || echo "0")
            echo "Found $SECRET_COUNT potential secrets"
            if [ "$SECRET_COUNT" -gt 0 ]; then
              echo "::warning::Found $SECRET_COUNT potential secrets in the codebase"
            fi
          fi
          
      - name: Dependency integrity check
        run: |
          echo "Checking dependency integrity..."
          
          # Check for git dependencies
          if grep -q '"source": "git"' sbom.json; then
            echo "::warning::Found git dependencies - these should be reviewed for security"
            
            # Extract git dependencies
            cat > extract-git-deps.py << 'EOF'
          import json
          
          with open('sbom.json', 'r') as f:
              sbom = json.load(f)
          
          git_deps = []
          for component in sbom.get('components', []):
              if component.get('purl', '').startswith('pkg:git/'):
                  git_deps.append({
                      'name': component.get('name'),
                      'version': component.get('version'),
                      'purl': component.get('purl')
                  })
          
          if git_deps:
              print("Git dependencies found:")
              for dep in git_deps:
                  print(f"  - {dep['name']} @ {dep['version']}")
          
          with open('git-dependencies.json', 'w') as f:
              json.dump({'git_dependencies': git_deps}, f, indent=2)
          EOF
          
            python3 extract-git-deps.py
          fi
          
      - name: Upload supply chain results
        uses: actions/upload-artifact@v4
        with:
          name: supply-chain-security-results
          path: |
            license-compliance-report.json
            secret-scan-results.json
            git-dependencies.json
          retention-days: 30

  # Merge and upload SARIF reports
  upload-security-results:
    runs-on: ubuntu-latest
    needs: [sast-scan, dependency-vulnerability-scan]
    if: always()
    permissions:
      security-events: write
      
    steps:
      - uses: actions/checkout@v4
      
      - name: Download all scan results
        uses: actions/download-artifact@v4
        with:
          path: scan-results/
          
      - name: Merge SARIF files
        run: |
          cat > merge-sarif.py << 'EOF'
          import json
          import glob
          import os
          from datetime import datetime
          
          def merge_sarif_files():
              merged_sarif = {
                  "version": "2.1.0",
                  "$schema": "https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json",
                  "runs": []
              }
              
              stats = {
                  "files_processed": 0,
                  "runs_merged": 0,
                  "total_results": 0
              }
              
              # Find all SARIF files
              sarif_files = glob.glob("scan-results/**/*.sarif", recursive=True)
              print(f"Found {len(sarif_files)} SARIF files to merge")
              
              for sarif_file in sarif_files:
                  try:
                      with open(sarif_file, 'r') as f:
                          sarif_data = json.load(f)
                      
                      if 'runs' in sarif_data:
                          for run in sarif_data['runs']:
                              # Count results
                              if 'results' in run:
                                  stats['total_results'] += len(run['results'])
                              
                              # Add metadata
                              if 'properties' not in run:
                                  run['properties'] = {}
                              run['properties']['sourceFile'] = os.path.basename(sarif_file)
                              
                              merged_sarif['runs'].append(run)
                              stats['runs_merged'] += 1
                          
                      stats['files_processed'] += 1
                      print(f"✓ Merged: {sarif_file}")
                  except Exception as e:
                      print(f"✗ Error processing {sarif_file}: {e}")
              
              # Add merge metadata
              merged_sarif['properties'] = {
                  'mergeStats': stats,
                  'mergeTimestamp': datetime.now().isoformat()
              }
              
              # Save merged file
              with open('merged-security-results.sarif', 'w') as f:
                  json.dump(merged_sarif, f, indent=2)
              
              print(f"\n=== Merge Summary ===")
              print(f"Files processed: {stats['files_processed']}")
              print(f"Runs merged: {stats['runs_merged']}")
              print(f"Total results: {stats['total_results']}")
              
              return stats['runs_merged'] > 0
          
          if __name__ == '__main__':
              success = merge_sarif_files()
              if not success:
                  print("Warning: No SARIF runs were merged")
          EOF
          
          python3 merge-sarif.py
          
      - name: Upload to GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: merged-security-results.sarif
          category: flutter-security
        continue-on-error: true
        
      - name: Upload merged SARIF as artifact
        uses: actions/upload-artifact@v4
        with:
          name: merged-security-sarif
          path: merged-security-results.sarif
          retention-days: 90

  # Generate unified security report
  unified-security-report:
    runs-on: ubuntu-latest
    needs: [dependency-vulnerability-scan, sast-scan, supply-chain-security]
    if: always()
    
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/
          
      - name: Generate unified security report
        run: |
          cat > generate-unified-report.py << 'EOF'
          import json
          import os
          import glob
          from datetime import datetime
          
          def load_json_file(filepath):
              try:
                  with open(filepath, 'r') as f:
                      return json.load(f)
              except:
                  return None
          
          def count_sarif_issues(sarif_data):
              issues = {'error': 0, 'warning': 0, 'note': 0}
              if sarif_data and 'runs' in sarif_data:
                  for run in sarif_data['runs']:
                      for result in run.get('results', []):
                          level = result.get('level', 'warning')
                          issues[level] = issues.get(level, 0) + 1
              return issues
          
          # Initialize unified report
          unified_report = {
              'timestamp': datetime.now().isoformat(),
              'summary': {
                  'scan_type': os.getenv('SCAN_TYPE', 'full'),
                  'total_vulnerabilities': 0,
                  'critical_vulnerabilities': 0,
                  'high_vulnerabilities': 0,
                  'medium_vulnerabilities': 0,
                  'low_vulnerabilities': 0,
                  'sast_issues': 0,
                  'dependency_issues': 0,
                  'supply_chain_issues': 0,
                  'license_compliant': True,
                  'secrets_found': 0,
                  'overall_score': 100
              },
              'details': {
                  'sast_analysis': {},
                  'dependency_scanning': {},
                  'supply_chain': {},
                  'recommendations': []
              }
          }# Process SAST reports
          sast_files = glob.glob('artifacts/sast-*-results/*.sarif')
          for sarif_file in sast_files:
              data = load_json_file(sarif_file)
              if data:
                  tool_name = os.path.basename(sarif_file).replace('-results.sarif', '')
                  unified_report['details']['sast_analysis'][tool_name] = data
                  issues = count_sarif_issues(data)
                  unified_report['summary']['sast_issues'] += sum(issues.values())
          
          # Process vulnerability scan results
          vuln_files = glob.glob('artifacts/vulnerability-scan-results/*.sarif')
          for sarif_file in vuln_files:
              data = load_json_file(sarif_file)
              if data:
                  tool_name = os.path.basename(sarif_file).replace('-results.sarif', '')
                  unified_report['details']['dependency_scanning'][tool_name] = data
                  issues = count_sarif_issues(data)
                  unified_report['summary']['critical_vulnerabilities'] += issues.get('error', 0)
                  unified_report['summary']['high_vulnerabilities'] += issues.get('warning', 0)
                  unified_report['summary']['medium_vulnerabilities'] += issues.get('note', 0)
          
          # Process OSV results
          osv_file = 'artifacts/vulnerability-scan-results/osv-results.json'
          if os.path.exists(osv_file):
              osv_data = load_json_file(osv_file)
              if osv_data and 'results' in osv_data:
                  unified_report['details']['dependency_scanning']['osv'] = osv_data
                  for result in osv_data.get('results', []):
                      severity = result.get('vulnerability', {}).get('severity', 'MEDIUM')
                      if severity == 'CRITICAL':
                          unified_report['summary']['critical_vulnerabilities'] += 1
                      elif severity == 'HIGH':
                          unified_report['summary']['high_vulnerabilities'] += 1
                      else:
                          unified_report['summary']['medium_vulnerabilities'] += 1
          
          # Process supply chain results
          license_file = 'artifacts/supply-chain-security-results/license-compliance-report.json'
          if os.path.exists(license_file):
              license_data = load_json_file(license_file)
              if license_data:
                  unified_report['details']['supply_chain']['license_compliance'] = license_data
                  unified_report['summary']['license_compliant'] = license_data.get('compliant', True)
                  if license_data.get('violations'):
                      unified_report['summary']['supply_chain_issues'] += len(license_data['violations'])
          
          secret_file = 'artifacts/supply-chain-security-results/secret-scan-results.json'
          if os.path.exists(secret_file):
              secret_data = load_json_file(secret_file)
              if secret_data:
                  # Count secrets (each line with SourceMetadata is a finding)
                  with open(secret_file, 'r') as f:
                      content = f.read()
                      secret_count = content.count('"SourceMetadata"')
                  unified_report['summary']['secrets_found'] = secret_count
                  unified_report['summary']['supply_chain_issues'] += secret_count
          
          # Calculate total vulnerabilities
          unified_report['summary']['total_vulnerabilities'] = (
              unified_report['summary']['critical_vulnerabilities'] +
              unified_report['summary']['high_vulnerabilities'] +
              unified_report['summary']['medium_vulnerabilities'] +
              unified_report['summary']['low_vulnerabilities']
          )
          
          unified_report['summary']['dependency_issues'] = unified_report['summary']['total_vulnerabilities']
          
          # Calculate overall score
          score_deductions = (
              unified_report['summary']['critical_vulnerabilities'] * 20 +
              unified_report['summary']['high_vulnerabilities'] * 10 +
              unified_report['summary']['medium_vulnerabilities'] * 5 +
              unified_report['summary']['low_vulnerabilities'] * 2 +
              unified_report['summary']['sast_issues'] * 3 +
              unified_report['summary']['supply_chain_issues'] * 5 +
              unified_report['summary']['secrets_found'] * 15
          )
          
          unified_report['summary']['overall_score'] = max(0, 100 - score_deductions)
          
          # Generate recommendations
          if unified_report['summary']['critical_vulnerabilities'] > 0:
              unified_report['details']['recommendations'].append({
                  'priority': 'CRITICAL',
                  'message': f"Fix {unified_report['summary']['critical_vulnerabilities']} critical vulnerabilities immediately"
              })
          
          if unified_report['summary']['high_vulnerabilities'] > 0:
              unified_report['details']['recommendations'].append({
                  'priority': 'HIGH',
                  'message': f"Address {unified_report['summary']['high_vulnerabilities']} high severity vulnerabilities"
              })
          
          if unified_report['summary']['secrets_found'] > 0:
              unified_report['details']['recommendations'].append({
                  'priority': 'CRITICAL',
                  'message': f"Remove {unified_report['summary']['secrets_found']} exposed secrets from the codebase"
              })
          
          if not unified_report['summary']['license_compliant']:
              unified_report['details']['recommendations'].append({
                  'priority': 'HIGH',
                  'message': 'Review and resolve license compliance issues'
              })
          
          if unified_report['summary']['sast_issues'] > 20:
              unified_report['details']['recommendations'].append({
                  'priority': 'MEDIUM',
                  'message': 'Improve code quality to reduce static analysis findings'
              })
          
          # Check for outdated dependencies
          outdated_file = 'artifacts/software-bill-of-materials/outdated.json'
          if os.path.exists(outdated_file):
              outdated_data = load_json_file(outdated_file)
              if outdated_data and 'packages' in outdated_data:
                  outdated_count = len(outdated_data['packages'])
                  if outdated_count > 10:
                      unified_report['details']['recommendations'].append({
                          'priority': 'LOW',
                          'message': f'Update {outdated_count} outdated dependencies'
                      })
          
          # Write unified report
          with open('unified-security-report.json', 'w') as f:
              json.dump(unified_report, f, indent=2)
          
          # Generate summary output
          print("=== Security Scan Summary ===")
          print(f"Overall Security Score: {unified_report['summary']['overall_score']}/100")
          print(f"Total Vulnerabilities: {unified_report['summary']['total_vulnerabilities']}")
          print(f"  - Critical: {unified_report['summary']['critical_vulnerabilities']}")
          print(f"  - High: {unified_report['summary']['high_vulnerabilities']}")
          print(f"  - Medium: {unified_report['summary']['medium_vulnerabilities']}")
          print(f"SAST Issues: {unified_report['summary']['sast_issues']}")
          print(f"Supply Chain Issues: {unified_report['summary']['supply_chain_issues']}")
          print(f"Secrets Found: {unified_report['summary']['secrets_found']}")
          print(f"License Compliant: {unified_report['summary']['license_compliant']}")
          
          # Exit with error if critical issues found
          if (unified_report['summary']['critical_vulnerabilities'] > 0 or 
              unified_report['summary']['secrets_found'] > 0 or
              unified_report['summary']['overall_score'] < 70):
              print("\n❌ Security scan failed due to critical issues")
              exit(1)
          else:
              print("\n✅ Security scan passed")
          EOF
          
          python3 generate-unified-report.py || echo "Security issues found"
          
      - name: Generate markdown report
        run: |
          cat > generate-markdown-report.py << 'EOF'
          import json
          from datetime import datetime
          
          with open('unified-security-report.json', 'r') as f:
              report = json.load(f)
          
          summary = report['summary']
          
          markdown = f"""# Flutter Security Scan Report
          
          Generated: {report['timestamp']}
          
          ## Summary
          
          **Overall Security Score: {summary['overall_score']}/100** {'✅' if summary['overall_score'] >= 70 else '❌'}
          
          ### Vulnerability Summary
          - **Total Vulnerabilities**: {summary['total_vulnerabilities']}
            - 🔴 Critical: {summary['critical_vulnerabilities']}
            - 🟠 High: {summary['high_vulnerabilities']}
            - 🟡 Medium: {summary['medium_vulnerabilities']}
            - 🟢 Low: {summary['low_vulnerabilities']}
          
          ### Other Findings
          - **SAST Issues**: {summary['sast_issues']}
          - **Supply Chain Issues**: {summary['supply_chain_issues']}
          - **Secrets Found**: {summary['secrets_found']} {'⚠️' if summary['secrets_found'] > 0 else '✅'}
          - **License Compliance**: {'✅ Compliant' if summary['license_compliant'] else '❌ Non-compliant'}
          
          ## Recommendations
          """
          
          for rec in report['details']['recommendations']:
              emoji = {'CRITICAL': '🔴', 'HIGH': '🟠', 'MEDIUM': '🟡', 'LOW': '🟢'}.get(rec['priority'], '⚪')
              markdown += f"\n- {emoji} **{rec['priority']}**: {rec['message']}"
          
          if not report['details']['recommendations']:
              markdown += "\n\n✅ No critical recommendations at this time."
          
          markdown += "\n\n---\n*Report generated by Flutter Security Pipeline*"
          
          with open('security-report.md', 'w') as f:
              f.write(markdown)
          
          # Also create a summary for PR comments
          pr_summary = f"""### 🔒 Security Scan Results
          
          **Score**: {summary['overall_score']}/100 {'✅' if summary['overall_score'] >= 70 else '❌'}
          
          | Type | Count |
          |------|-------|
          | 🔴 Critical | {summary['critical_vulnerabilities']} |
          | 🟠 High | {summary['high_vulnerabilities']} |
          | 🟡 Medium | {summary['medium_vulnerabilities']} |
          | 🔍 SAST | {summary['sast_issues']} |
          | 🔑 Secrets | {summary['secrets_found']} |
          
          [View Full Report](https://github.com/${{github.repository}}/actions/runs/${{github.run_id}})
          """
          
          with open('pr-comment.md', 'w') as f:
              f.write(pr_summary)
          EOF
          
          python3 generate-markdown-report.py
          
      - name: Upload unified security report
        uses: actions/upload-artifact@v4
        with:
          name: unified-security-report
          path: |
            unified-security-report.json
            security-report.md
            pr-comment.md
          retention-days: 90
          
      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const comment = fs.readFileSync('pr-comment.md', 'utf8');
            
            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(comment => 
              comment.user.type === 'Bot' && 
              comment.body.includes('🔒 Security Scan Results')
            );
            
            if (botComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }
          
      - name: Security scan summary
        run: |
          echo "================================================"
          echo "Flutter Security Pipeline Execution Complete"
          echo "================================================"
          echo ""
          cat security-report.md
          echo ""
          echo "================================================"
          echo "Artifacts Generated:"
          echo "- Software Bill of Materials (SBOM)"
          echo "- Vulnerability Scan Results"
          echo "- SAST Analysis Reports"
          echo "- Supply Chain Security Report"
          echo "- Unified Security Report"
          echo ""
          echo "View detailed results in GitHub Security tab and workflow artifacts"
          echo "================================================"
